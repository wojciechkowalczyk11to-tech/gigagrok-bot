# GigaGrok â€” Phase Prompts for Claude Code

Plik zawiera kompletne prompty do realizacji kaÅ¼dej fazy projektu GigaGrok.
KaÅ¼dy prompt jest samowystarczalny â€” zawiera peÅ‚ny kontekst, zasady i specyfikacjÄ™.

UÅ¼ycie:
```bash
cd ~/gigagrok-bot
claude "Realizujemy FazÄ™ N. [wklej prompt fazy N]"
```

Lub automatycznie:
```bash
claude "$(cat PHASE_PROMPTS.md | sed -n '/^## PROMPT: FAZA 1$/,/^## PROMPT: FAZA 2$/p' | head -n -1)"
```

---

## PROMPT: FAZA 1

JesteÅ› ekspertem od budowy Telegram botÃ³w z Python i xAI API. Realizujesz FAZÄ˜ 1 projektu GigaGrok â€” fundament bota z Grok 4.1 Fast Reasoning.

ZASADY ABSOLUTNE:
- Zero placeholderÃ³w, zero TODO, zero "implement later", zero "add here"
- KaÅ¼dy plik musi byÄ‡ KOMPLETNY i gotowy do uruchomienia
- Type hints wszÄ™dzie
- Logowanie z structlog
- ObsÅ‚uga bÅ‚Ä™dÃ³w na KAÅ»DYM poziomie â€” Å¼aden exception nie moÅ¼e wylecieÄ‡ do usera bez czytelnego komunikatu
- Webhook mode (NIE polling) â€” bot nasÅ‚uchuje na localhost:8443
- Single-user bot â€” tylko ADMIN_USER_ID ma dostÄ™p

STACK:
- Python 3.12
- python-telegram-bot==21.0.1
- httpx==0.27.0
- aiosqlite==0.20.0
- pydantic-settings==2.1.0
- structlog
- python-dotenv==1.0.1

STRUKTURA PLIKÃ“W DO STWORZENIA:
```
gigagrok-bot/
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â”œâ”€â”€ grok_client.py
â”œâ”€â”€ db.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ start.py
â”‚   â””â”€â”€ chat.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

=== SPECYFIKACJA KAÅ»DEGO PLIKU ===

1. config.py â€” Pydantic BaseSettings z .env:

```python
# Wymagane:
XAI_API_KEY: str              # xAI API key z console.x.ai
TELEGRAM_BOT_TOKEN: str       # Token od @BotFather
ADMIN_USER_ID: int            # TwÃ³j Telegram user ID
WEBHOOK_URL: str              # "https://grok.nexus-oc.pl"
WEBHOOK_PATH: str = "webhook" # Path for webhook
WEBHOOK_PORT: int = 8443      # Port lokalny
WEBHOOK_SECRET: str           # Losowy string do weryfikacji

# Opcjonalne z domyÅ›lnymi:
XAI_BASE_URL: str = "https://api.x.ai/v1"
XAI_MODEL_REASONING: str = "grok-4-1-fast-reasoning"
XAI_MODEL_FAST: str = "grok-4-1-fast"
DB_PATH: str = "gigagrok.db"
MAX_HISTORY: int = 20
MAX_OUTPUT_TOKENS: int = 16000
DEFAULT_REASONING_EFFORT: str = "high"  # low/medium/high
LOG_LEVEL: str = "INFO"
```

System prompt (wbudowany w config jako staÅ‚a, NIE w .env):
```
JesteÅ› GigaGrok â€” najinteligentniejszy asystent AI zasilany Grok 4.1 Fast Reasoning.

Twoje cechy:
- MyÅ›lisz gÅ‚Ä™boko przed odpowiedziÄ… (chain-of-thought reasoning)
- Odpowiadasz konkretnie, bez zbÄ™dnego fluffu
- Kod formatujesz w blokach z oznaczeniem jÄ™zyka
- JesteÅ› ekspertem od programowania, analizy danych, strategii biznesowej
- MÃ³wisz po polsku gdy pytany po polsku, po angielsku gdy po angielsku
- JesteÅ› szczery â€” mÃ³wisz "nie wiem" gdy nie wiesz
- Przy zÅ‚oÅ¼onych problemach rozkÅ‚adasz je na kroki

Formatowanie:
- Markdown
- Kod w blokach ```jÄ™zyk
- Listy numerowane dla krokÃ³w
- Pogrubienie dla kluczowych pojÄ™Ä‡
- BÄ…dÅº zwiÄ™zÅ‚y ale kompletny

Aktualna data: {current_date}
```

2. db.py â€” Async SQLite z aiosqlite:

Tabele:
```sql
CREATE TABLE IF NOT EXISTS conversations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    role TEXT NOT NULL,           -- 'user', 'assistant', 'system'
    content TEXT NOT NULL,
    reasoning_content TEXT,       -- reasoning tokens content (jeÅ›li dostÄ™pne)
    model TEXT,
    tokens_in INTEGER DEFAULT 0,
    tokens_out INTEGER DEFAULT 0,
    reasoning_tokens INTEGER DEFAULT 0,
    cost_usd REAL DEFAULT 0.0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS user_settings (
    user_id INTEGER PRIMARY KEY,
    system_prompt TEXT,
    reasoning_effort TEXT DEFAULT 'high',
    voice_enabled INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS usage_stats (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    date TEXT NOT NULL,           -- 'YYYY-MM-DD'
    total_requests INTEGER DEFAULT 0,
    total_tokens_in INTEGER DEFAULT 0,
    total_tokens_out INTEGER DEFAULT 0,
    total_reasoning_tokens INTEGER DEFAULT 0,
    total_cost_usd REAL DEFAULT 0.0,
    UNIQUE(user_id, date)
);

CREATE INDEX IF NOT EXISTS idx_conv_user_time ON conversations(user_id, created_at DESC);
CREATE INDEX IF NOT EXISTS idx_stats_user_date ON usage_stats(user_id, date);
```

Funkcje:
- async init_db() â€” tworzy tabele
- async save_message(user_id, role, content, reasoning_content=None, model=None, tokens_in=0, tokens_out=0, reasoning_tokens=0, cost_usd=0.0) â€” zapisz wiadomoÅ›Ä‡
- async get_history(user_id, limit=20) -> list[dict] â€” pobierz historiÄ™ (role, content)
- async clear_history(user_id) -> int â€” wyczyÅ›Ä‡, zwrÃ³Ä‡ ile usuniÄ™to
- async update_daily_stats(user_id, tokens_in, tokens_out, reasoning_tokens, cost_usd) â€” aktualizuj stats
- async get_daily_stats(user_id, date=None) -> dict â€” dzisiejsze statystyki
- async get_all_time_stats(user_id) -> dict â€” Å‚Ä…czne statystyki
- async set_user_setting(user_id, key, value) â€” zapisz ustawienie
- async get_user_setting(user_id, key) -> str|None â€” pobierz ustawienie

Kalkulacja kosztÃ³w (staÅ‚e w pliku):
```python
COST_PER_M_INPUT = 0.20    # $0.20 per 1M input tokens
COST_PER_M_OUTPUT = 0.50   # $0.50 per 1M output tokens (reasoning tokens teÅ¼)

def calculate_cost(tokens_in: int, tokens_out: int, reasoning_tokens: int) -> float:
    input_cost = (tokens_in / 1_000_000) * COST_PER_M_INPUT
    output_cost = ((tokens_out + reasoning_tokens) / 1_000_000) * COST_PER_M_OUTPUT
    return round(input_cost + output_cost, 6)
```

3. grok_client.py â€” xAI API Client:

Klasa GrokClient:
- __init__(api_key, base_url) â€” tworzy httpx.AsyncClient z timeout=120s
- async chat_stream(messages, model, reasoning_effort=None, tools=None) â€” generator yielding tuples:
  * Yield: ("content", chunk_text) | ("reasoning", chunk_text) | ("status", status_msg) | ("done", usage_dict)
  * usage_dict: {"prompt_tokens": int, "completion_tokens": int, "reasoning_tokens": int}
- async chat(messages, model, reasoning_effort=None, tools=None) -> dict â€” non-streaming, zwraca peÅ‚nÄ… odpowiedÅº
- async close() â€” zamknij client

Implementacja streaming:
```
POST {base_url}/chat/completions
Headers: Authorization: Bearer {api_key}, Content-Type: application/json
Body:
{
    "model": "grok-4-1-fast-reasoning",
    "messages": [...],
    "stream": true,
    "max_tokens": 16000,
    "reasoning": {"effort": "high"}   // TYLKO dla modelu reasoning, pomiÅ„ dla fast
}

Response SSE format (OpenAI-compatible):
data: {"id":"...","choices":[{"index":0,"delta":{"reasoning_content":"thinking..."}}]}
data: {"id":"...","choices":[{"index":0,"delta":{"content":"Hello"}}]}
data: {"id":"...","choices":[{"index":0,"delta":{},"finish_reason":"stop"}],"usage":{"prompt_tokens":10,"completion_tokens":50,"completion_tokens_details":{"reasoning_tokens":30}}}
data: [DONE]
```

WAÅ»NE:
- reasoning_content przychodzi PRZED content
- usage przychodzi w ostatnim DONE-adjacent chunk lub w chunk z finish_reason
- reasoning_tokens sÄ… w usage.completion_tokens_details.reasoning_tokens
- Parametr "reasoning" dodawaj TYLKO dla modelu reasoning, NIE dla fast
- Retry z exponential backoff: 3 prÃ³by, 1s/2s/4s delay
- Timeout: 120s (reasoning moÅ¼e trwaÄ‡ dÅ‚ugo)

4. utils.py â€” Helpery:

- escape_html(text: str) -> str â€” escape < > & dla HTML parse mode
- split_message(text: str, max_length: int = 4000) -> list[str] â€” dziel na kawaÅ‚ki dla Telegrama (limit 4096)
  - Dziel po podwÃ³jnym newline, potem po newline, potem po spacji
  - Nigdy nie tnij w Å›rodku bloku kodu (``` ... ```)
- format_footer(model: str, tokens_in: int, tokens_out: int, reasoning_tokens: int, cost_usd: float, elapsed_seconds: float) -> str
  - Format: "âš™ï¸ grok-4-1-fast-reasoning | ğŸ“¥ 234 ğŸ“¤ 567 ğŸ§  890 | ğŸ’° $0.0004 | â± 3.2s"
- format_number(n: int) -> str â€” 1234 â†’ "1.2K", 1234567 â†’ "1.2M"
- get_current_date() -> str â€” "2026-02-23"

5. handlers/start.py:

/start â€” Powitanie:
```
ğŸ§  **GigaGrok** â€” TwÃ³j asystent AI

Zasilany przez **Grok 4.1 Fast Reasoning**
â€¢ 2M tokenÃ³w kontekstu
â€¢ Deep reasoning (chain-of-thought)
â€¢ Web search, X search, code execution
â€¢ Analiza obrazÃ³w i dokumentÃ³w

WyÅ›lij mi wiadomoÅ›Ä‡, a odpowiem z peÅ‚nÄ… mocÄ… reasoning.

Wpisz /help po listÄ™ komend.
```

/help â€” Lista komend (sformatowana czytelnie):
```
ğŸ“š **Komendy GigaGrok**

ğŸ’¬ **Chat:**
WyÅ›lij wiadomoÅ›Ä‡ â†’ odpowiedÅº z reasoning

âš¡ **/fast** <tekst> â†’ szybka odpowiedÅº bez reasoning
ğŸ§  **/think** <tekst> â†’ deep reasoning mode
ğŸ” **/websearch** <query> â†’ szukaj w internecie
ğŸ¦ **/xsearch** <query> â†’ szukaj na X/Twitter
ğŸ’» **/code** <prompt> â†’ generuj i uruchom kod
ğŸ”¬ **/analyze** <tekst> â†’ gÅ‚Ä™boka analiza
ğŸ–¼ **/image** â†’ wyÅ›lij zdjÄ™cie do analizy
ğŸ“ **/file** â†’ wyÅ›lij plik do analizy
ğŸš€ **/gigagrok** <prompt> â†’ FULL POWER mode

âš™ï¸ **Ustawienia:**
/system <prompt> â†’ ustaw system prompt
/clear â†’ wyczyÅ›Ä‡ historiÄ™
/stats â†’ statystyki uÅ¼ycia
/voice â†’ toggle odpowiedzi gÅ‚osowych

ğŸ“¦ **/collection** â†’ zarzÄ…dzaj bazÄ… wiedzy
ğŸ“¥ **/export** â†’ eksportuj historiÄ™
```

6. handlers/chat.py â€” GÅ‚Ã³wny handler wiadomoÅ›ci:

Workflow:
```python
async def handle_message(update, context):
    user_id = update.effective_user.id
    
    # 1. Auth check
    if user_id != settings.admin_user_id:
        await update.message.reply_text("â›” Brak dostÄ™pu.")
        return
    
    query = update.message.text
    
    # 2. Pobierz historiÄ™ z DB
    history = await db.get_history(user_id, limit=settings.max_history)
    
    # 3. Pobierz custom system prompt (lub domyÅ›lny)
    custom_prompt = await db.get_user_setting(user_id, "system_prompt")
    system_prompt = custom_prompt or DEFAULT_SYSTEM_PROMPT.format(current_date=get_current_date())
    
    # 4. Zbuduj messages
    messages = [{"role": "system", "content": system_prompt}]
    for msg in history:
        messages.append({"role": msg["role"], "content": msg["content"]})
    messages.append({"role": "user", "content": query})
    
    # 5. WyÅ›lij placeholder
    sent = await update.message.reply_text("ğŸ§  <i>Grok myÅ›li...</i>", parse_mode="HTML")
    
    # 6. Stream odpowiedzi
    start_time = time.time()
    full_content = ""
    full_reasoning = ""
    usage = {}
    last_edit = 0
    
    try:
        async for event_type, data in grok.chat_stream(messages, model=settings.xai_model_reasoning, reasoning_effort=settings.default_reasoning_effort):
            if event_type == "reasoning":
                full_reasoning += data
                # Opcjonalnie: pokaÅ¼ "ğŸ§  Reasoning..." z dÅ‚ugoÅ›ciÄ…
                now = time.time()
                if now - last_edit > 2.0:
                    await sent.edit_text(f"ğŸ§  <i>Grok myÅ›li... ({len(full_reasoning)} znakÃ³w reasoning)</i>", parse_mode="HTML")
                    last_edit = now
            
            elif event_type == "content":
                full_content += data
                now = time.time()
                if now - last_edit > 1.5:
                    display = full_content[:3800]
                    if len(full_content) > 3800:
                        display += "\n\n<i>... (kontynuacja)</i>"
                    try:
                        await sent.edit_text(display, parse_mode="HTML")
                    except Exception:
                        pass  # Ignore edit errors (content unchanged, rate limit)
                    last_edit = now
            
            elif event_type == "done":
                usage = data
    
    except Exception as e:
        logger.error("Grok API error", error=str(e))
        await sent.edit_text(f"âŒ BÅ‚Ä…d API: {escape_html(str(e))}", parse_mode="HTML")
        return
    
    # 7. Finalna wiadomoÅ›Ä‡ z footerem
    elapsed = time.time() - start_time
    tokens_in = usage.get("prompt_tokens", 0)
    tokens_out = usage.get("completion_tokens", 0)
    reasoning_tokens = usage.get("reasoning_tokens", 0)
    cost = calculate_cost(tokens_in, tokens_out, reasoning_tokens)
    
    footer = format_footer(settings.xai_model_reasoning, tokens_in, tokens_out, reasoning_tokens, cost, elapsed)
    
    # 8. WyÅ›lij finalnÄ… wersjÄ™ (podziel jeÅ›li za dÅ‚uga)
    final_text = f"{full_content}\n\n<code>{footer}</code>"
    parts = split_message(final_text, max_length=4000)
    
    await sent.edit_text(parts[0], parse_mode="HTML")
    for part in parts[1:]:
        await update.message.reply_text(part, parse_mode="HTML")
    
    # 9. Zapisz do DB
    await db.save_message(user_id, "user", query)
    await db.save_message(user_id, "assistant", full_content, reasoning_content=full_reasoning, model=settings.xai_model_reasoning, tokens_in=tokens_in, tokens_out=tokens_out, reasoning_tokens=reasoning_tokens, cost_usd=cost)
    await db.update_daily_stats(user_id, tokens_in, tokens_out, reasoning_tokens, cost)
```

7. main.py â€” Entry point:

```python
# Webhook mode:
application = Application.builder().token(settings.telegram_bot_token).build()

# Rejestracja handlerÃ³w
application.add_handler(CommandHandler("start", start_command))
application.add_handler(CommandHandler("help", help_command))
application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

# Webhook setup
await application.bot.set_webhook(
    url=f"{settings.webhook_url}/{settings.webhook_path}",
    secret_token=settings.webhook_secret,
    allowed_updates=["message", "callback_query"],
)

# Run webhook server
application.run_webhook(
    listen="0.0.0.0",
    port=settings.webhook_port,
    url_path=settings.webhook_path,
    webhook_url=f"{settings.webhook_url}/{settings.webhook_path}",
    secret_token=settings.webhook_secret,
)
```

8. requirements.txt:
```
python-telegram-bot==21.0.1
httpx==0.27.0
aiosqlite==0.20.0
pydantic-settings==2.1.0
structlog
python-dotenv==1.0.1
```

9. .env.example:
```bash
# === REQUIRED ===
XAI_API_KEY=your_xai_api_key_from_console.x.ai
TELEGRAM_BOT_TOKEN=your_bot_token_from_botfather
ADMIN_USER_ID=your_telegram_user_id

# === WEBHOOK (grok.nexus-oc.pl) ===
WEBHOOK_URL=https://grok.nexus-oc.pl
WEBHOOK_PATH=webhook
WEBHOOK_PORT=8443
WEBHOOK_SECRET=wygeneruj_losowy_string_32_znaki

# === OPTIONAL ===
# XAI_BASE_URL=https://api.x.ai/v1
# XAI_MODEL_REASONING=grok-4-1-fast-reasoning
# XAI_MODEL_FAST=grok-4-1-fast
# DB_PATH=gigagrok.db
# MAX_HISTORY=20
# MAX_OUTPUT_TOKENS=16000
# DEFAULT_REASONING_EFFORT=high
# LOG_LEVEL=INFO
```

10. .gitignore:
```
__pycache__/
*.py[cod]
*.so
.env
.env.local
*.db
*.sqlite3
venv/
.venv/
*.log
.DS_Store
.vscode/
.idea/
```

11. README.md:
```markdown
# ğŸ§  GigaGrok

Telegram bot powered by Grok 4.1 Fast Reasoning.

## Setup
1. `pip install -r requirements.txt`
2. `cp .env.example .env` â€” uzupeÅ‚nij klucze
3. `python main.py`

## Requirements
- Python 3.12+
- xAI API key (console.x.ai)
- Telegram Bot token (@BotFather)
- Cloudflare Tunnel na grok.nexus-oc.pl â†’ localhost:8443
```

WYGENERUJ WSZYSTKIE PLIKI. Kompletne, gotowe do uruchomienia po `pip install -r requirements.txt && python main.py`.

## PROMPT: FAZA 2

Realizujesz FAZÄ˜ 2 projektu GigaGrok. Repo ma juÅ¼ dziaÅ‚ajÄ…cy fundament z Fazy 1.

KONTEKST REPO:
- main.py â€” entry point z webhook
- config.py â€” Pydantic settings
- grok_client.py â€” xAI API client ze streaming
- db.py â€” SQLite z historiÄ… i stats
- utils.py â€” helpery (escape, split, footer)
- handlers/start.py â€” /start, /help
- handlers/chat.py â€” obsÅ‚uga wiadomoÅ›ci ze streaming

ZASADY: Zero placeholderÃ³w. Kompletny, dziaÅ‚ajÄ…cy kod. Type hints. Error handling.

ZADANIA:

1. StwÃ³rz handlers/mode.py:

/fast <prompt> â€” OdpowiedÅº BEZ reasoning:
- Model: config.XAI_MODEL_FAST ("grok-4-1-fast")
- NIE dodawaj parametru "reasoning" do API request
- Streaming jak w chat.py ale bez reasoning status
- Footer z info Å¼e to tryb FAST
- JeÅ›li brak promptu po /fast â†’ "Podaj prompt po /fast"

/think <prompt> â€” Deep reasoning:
- Model: config.XAI_MODEL_REASONING
- reasoning.effort = "high" ZAWSZE (override usera)
- PokaÅ¼ w streamie: "ğŸ§  Deep reasoning... (X znakÃ³w)"
- Footer z reasoning tokens wyrÃ³Å¼nione
- JeÅ›li brak promptu â†’ "Podaj prompt po /think"

/clear â€” WyczyÅ›Ä‡ historiÄ™:
- WywoÅ‚aj db.clear_history(user_id)
- Odpowiedz: "ğŸ—‘ Wyczyszczono X wiadomoÅ›ci z historii."

2. StwÃ³rz handlers/settings.py:

/system â€” ZarzÄ…dzanie system promptem:
- /system (bez args) â†’ pokaÅ¼ aktualny prompt (skrÃ³cony do 500 znakÃ³w)
- /system reset â†’ przywrÃ³Ä‡ domyÅ›lny, potwierdÅº
- /system <tekst> â†’ zapisz jako custom system prompt
  - Zapisz do db.set_user_setting(user_id, "system_prompt", tekst)
  - PotwierdÅº: "âœ… System prompt ustawiony (X znakÃ³w)"

/stats â€” Statystyki:
- Pobierz daily stats i all-time stats
- Format:
```
ğŸ“Š **Statystyki GigaGrok**

ğŸ“… Dzisiaj:
  Zapytania: 15
  Tokeny: ğŸ“¥ 12.3K  ğŸ“¤ 8.7K  ğŸ§  5.2K
  Koszt: $0.0089

ğŸ“ˆ ÅÄ…cznie:
  Zapytania: 234
  Tokeny: ğŸ“¥ 180K  ğŸ“¤ 95K  ğŸ§  67K
  Koszt: $0.142

âš™ï¸ Tryb: reasoning (high)
ğŸ“ System prompt: [domyÅ›lny | custom (234 znakÃ³w)]
```

3. Zmodyfikuj grok_client.py:
- Metoda chat_stream() i chat() muszÄ… przyjmowaÄ‡ parametr model: str
- JeÅ›li model nie zawiera "reasoning" w nazwie â†’ NIE dodawaj parametru "reasoning" do body
- Reszta bez zmian

4. Zmodyfikuj handlers/chat.py:
- Pobieraj system prompt z DB (custom) lub config (domyÅ›lny)
- To powinno juÅ¼ dziaÅ‚aÄ‡ z Fazy 1, ale upewnij siÄ™

5. Zaktualizuj main.py â€” dodaj rejestracjÄ™:
```python
application.add_handler(CommandHandler("fast", fast_command))
application.add_handler(CommandHandler("think", think_command))
application.add_handler(CommandHandler("clear", clear_command))
application.add_handler(CommandHandler("system", system_command))
application.add_handler(CommandHandler("stats", stats_command))
```

6. Zaktualizuj handlers/start.py /help â€” dodaj nowe komendy do listy.

Wygeneruj WSZYSTKIE nowe pliki i POKAÅ» DOKÅADNE ZMIANY w istniejÄ…cych plikach.

## PROMPT: FAZA 3

Realizujesz FAZÄ˜ 3 projektu GigaGrok â€” Agent Tools API (web search, X search, code execution, analiza).

KONTEKST REPO: Fazy 1-2 zrealizowane. Bot ma chat, /fast, /think, /clear, /stats, /system.

KLUCZOWA INFORMACJA O xAI AGENT TOOLS:
Agent Tools API dziaÅ‚a SERVER-SIDE. Nie implementujesz logiki narzÄ™dzi â€” xAI robi to za ciebie.
Dodajesz parametr "tools" do API request i Grok sam decyduje kiedy i jak uÅ¼yÄ‡ narzÄ™dzi.
Tool calls sÄ… DARMOWE ($0 za invocation). PÅ‚acisz tylko za tokeny.

xAI API FORMAT Z TOOLS:
```json
{
    "model": "grok-4-1-fast-reasoning",
    "messages": [...],
    "stream": true,
    "reasoning": {"effort": "high"},
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "web_search",
                "description": "Search the web for current information"
            }
        },
        {
            "type": "function",
            "function": {
                "name": "x_search",
                "description": "Search posts on X (Twitter)"
            }
        },
        {
            "type": "function",
            "function": {
                "name": "code_execution",
                "description": "Execute code in a sandboxed environment"
            }
        }
    ]
}
```

STREAMING Z TOOL CALLS:
Gdy Grok decyduje o uÅ¼yciu narzÄ™dzia, stream zawiera:
1. reasoning_content â€” "Let me search for this..."
2. finish_reason: "tool_calls" + tool_calls array
3. [xAI EXECUTES TOOL SERVER-SIDE]
4. Nowy set of deltas z content (po tool execution)

W response SSE:
```
data: {"choices":[{"delta":{"reasoning_content":"I should search..."}}]}
data: {"choices":[{"delta":{"tool_calls":[{"function":{"name":"web_search","arguments":"{\"query\":\"...\"}"}}]}}]}
data: {"choices":[{"delta":{"content":"Based on my search..."}}]}
```

Grok moÅ¼e wywoÅ‚aÄ‡ WIELE narzÄ™dzi w jednym zapytaniu, sekwencyjnie.

ZADANIA:

1. StwÃ³rz tools.py â€” Definicje narzÄ™dzi:
```python
TOOL_WEB_SEARCH = {
    "type": "function",
    "function": {
        "name": "web_search",
        "description": "Search the internet for current information, news, facts, documentation"
    }
}

TOOL_X_SEARCH = {
    "type": "function",
    "function": {
        "name": "x_search",
        "description": "Search posts and discussions on X (Twitter)"
    }
}

TOOL_CODE_EXEC = {
    "type": "function",
    "function": {
        "name": "code_execution",
        "description": "Execute code in a sandboxed environment. Supports Python, JavaScript, and more."
    }
}

TOOLS_ALL = [TOOL_WEB_SEARCH, TOOL_X_SEARCH, TOOL_CODE_EXEC]

def get_tools(command: str) -> list[dict]:
    """ZwrÃ³Ä‡ tools dla danej komendy."""
    mapping = {
        "websearch": [TOOL_WEB_SEARCH],
        "xsearch": [TOOL_X_SEARCH],
        "code": [TOOL_CODE_EXEC],
        "analyze": [TOOL_WEB_SEARCH, TOOL_CODE_EXEC],
        "gigagrok": TOOLS_ALL,
    }
    return mapping.get(command, [])
```

2. Zmodyfikuj grok_client.py:
- Dodaj parametr tools: list[dict] | None do chat_stream() i chat()
- JeÅ›li tools â†’ dodaj "tools" do request body
- W streaming: obsÅ‚uÅ¼ delta z tool_calls:
  - Gdy delta ma tool_calls â†’ yield ("tool_use", tool_name)
  - Potem kontynuuj zbieranie content
- WAÅ»NE: xAI wykonuje toole server-side, wiÄ™c po tool_calls delta dalej lecÄ… content deltas z wynikami

3. StwÃ³rz handlers/search.py:

/websearch <query>:
- SprawdÅº auth
- System prompt: "Przeszukaj internet i podaj aktualne, szczegÃ³Å‚owe informacje na temat: {query}. Cytuj ÅºrÃ³dÅ‚a z URL. Strukturyzuj odpowiedÅº."
- tools=[TOOL_WEB_SEARCH]
- Model: reasoning z effort=medium (web search nie potrzebuje heavy reasoning)
- Status: "ğŸ” Szukam w internecie..."
- Streaming + footer

/xsearch <query>:
- System prompt: "Przeszukaj X/Twitter i podaj najnowsze posty i dyskusje na temat: {query}. Podaj autorÃ³w (@handle), daty i treÅ›Ä‡. Podsumuj nastroje/trendy."
- tools=[TOOL_X_SEARCH]
- Model: reasoning z effort=medium
- Status: "ğŸ¦ Szukam na X/Twitter..."
- Streaming + footer

4. StwÃ³rz handlers/code.py:

/code <prompt>:
- System prompt: "Wygeneruj czysty, produkcyjny kod. JeÅ›li to moÅ¼liwe â€” uruchom go w sandboxie i pokaÅ¼ output. JÄ™zyk: wykryj z kontekstu lub Python domyÅ›lnie. Tylko kod i output, minimalne wyjaÅ›nienia."
- tools=[TOOL_CODE_EXEC]
- Model: reasoning z effort=medium
- Status: "ğŸ’» GenerujÄ™ kod..."
- JeÅ›li output kodu > 4000 znakÃ³w â†’ wyÅ›lij jako plik .txt

5. StwÃ³rz handlers/analyze.py:

/analyze <tekst lub reply na wiadomoÅ›Ä‡>:
- JeÅ›li reply na wiadomoÅ›Ä‡ â†’ pobierz tekst reply jako input
- JeÅ›li tekst po /analyze â†’ uÅ¼yj jako input
- System prompt: "PrzeprowadÅº gÅ‚Ä™bokÄ…, wielowarstwowÄ… analizÄ™ poniÅ¼szego tekstu/tematu. RozÅ‚Ã³Å¼ na czynniki pierwsze. UÅ¼yj web search do weryfikacji faktÃ³w. JeÅ›li potrzebne obliczenia â€” uruchom kod. Strukturyzuj wyniki: 1) Podsumowanie 2) Kluczowe wnioski 3) Analiza szczegÃ³Å‚owa 4) Rekomendacje."
- tools=[TOOL_WEB_SEARCH, TOOL_CODE_EXEC]
- Model: reasoning z effort=high
- Status: "ğŸ”¬ AnalizujÄ™ gÅ‚Ä™boko..."

6. Zaktualizuj main.py â€” rejestracja:
```python
application.add_handler(CommandHandler("websearch", websearch_command))
application.add_handler(CommandHandler("xsearch", xsearch_command))
application.add_handler(CommandHandler("code", code_command))
application.add_handler(CommandHandler("analyze", analyze_command))
```

7. Zaktualizuj /help w start.py.

Wygeneruj WSZYSTKIE nowe pliki i DOKÅADNE ZMIANY w istniejÄ…cych.

## PROMPT: FAZA 4

Realizujesz FAZÄ˜ 4 projektu GigaGrok â€” Multimodal (obrazy i pliki).

KONTEKST REPO: Fazy 1-3 zrealizowane. Bot ma chat, tryby, agent tools (web, X, code, analyze).

xAI MULTIMODAL API â€” IMAGE INPUT:
Grok 4.1 Fast przyjmuje obrazy jako base64 w messages (format OpenAI-compatible):
```json
{
    "messages": [{
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": "data:image/jpeg;base64,{base64_data}"
                }
            },
            {
                "type": "text",
                "text": "Opisz co widzisz"
            }
        ]
    }]
}
```
Ograniczenia: JPEG/PNG only, max 5MB per image, 256-1792 tokenÃ³w per obraz.

ZADANIA:

1. StwÃ³rz file_utils.py:

```python
import base64, io, zipfile
from pathlib import Path

async def image_to_base64(file_bytes: bytes, max_size_mb: float = 5.0) -> tuple[str, str]:
    """Konwertuj obraz do base64. Kompresuj jeÅ›li za duÅ¼y. ZwrÃ³Ä‡ (base64_str, mime_type)."""
    # UÅ¼yj Pillow do resize/compress jeÅ›li > max_size_mb
    # ZwrÃ³Ä‡ base64 string i mime type (image/jpeg lub image/png)

async def extract_text_from_pdf(file_bytes: bytes) -> str:
    """WyciÄ…gnij tekst z PDF uÅ¼ywajÄ…c pdfplumber."""

async def extract_text_from_docx(file_bytes: bytes) -> str:
    """WyciÄ…gnij tekst z DOCX uÅ¼ywajÄ…c python-docx."""

async def extract_text_from_zip(file_bytes: bytes) -> dict[str, str]:
    """Wypakuj ZIP, zwrÃ³Ä‡ dict {filename: content} dla plikÃ³w tekstowych."""
    # ObsÅ‚uÅ¼: .txt, .md, .py, .js, .json, .csv, .xml, .html, .yaml, .toml
    # Ignoruj: binarne, obrazy, > 1MB per plik

def smart_truncate(text: str, max_chars: int = 100_000) -> str:
    """JeÅ›li tekst > max_chars: zachowaj 40% z poczÄ…tku + 40% z koÅ„ca + info o obciÄ™ciu."""

def detect_file_type(filename: str) -> str:
    """ZwrÃ³Ä‡ kategoriÄ™: 'image', 'pdf', 'docx', 'zip', 'text', 'unknown'."""
    # Na podstawie rozszerzenia
```

2. StwÃ³rz handlers/image.py:

Auto-detect zdjÄ™Ä‡ â€” MessageHandler na filters.PHOTO:
- Pobierz najwiÄ™kszÄ… wersjÄ™ zdjÄ™cia (update.message.photo[-1])
- Pobierz file z Telegram API (await context.bot.get_file(file_id))
- Pobierz bytes (await file.download_as_bytearray())
- Konwertuj do base64
- Prompt domyÅ›lny: "SzczegÃ³Å‚owo opisz i przeanalizuj ten obraz. Co widzisz? Jakie wnioski?"
- JeÅ›li user dodaÅ‚ caption â†’ uÅ¼yj jako prompt zamiast domyÅ›lnego
- WyÅ›lij do Grok jako multimodal message
- Streaming + footer

/image jako reply na zdjÄ™cie + tekst:
- Pobierz zdjÄ™cie z replied message
- Tekst po /image jako prompt
- j.w.

3. StwÃ³rz handlers/file.py:

Auto-detect plikÃ³w â€” MessageHandler na filters.Document.ALL:
- Pobierz dokument (update.message.document)
- Pobierz bytes
- Rozpoznaj typ (detect_file_type)
- Routing:
  * image â†’ przekieruj do logiki image handler
  * pdf â†’ extract_text_from_pdf â†’ wyÅ›lij do Grok
  * docx â†’ extract_text_from_docx â†’ wyÅ›lij do Grok
  * zip â†’ extract_text_from_zip â†’ wyÅ›lij do Grok z listÄ… plikÃ³w
  * text (.txt, .md, .py, .js, .json, .csv, .xml, .html) â†’ odczytaj jako tekst
  * unknown â†’ "NieobsÅ‚ugiwany format pliku"
- Smart truncation jeÅ›li tekst > 100K znakÃ³w
- Caption jako prompt (lub domyÅ›lny: "Przeanalizuj ten plik")
- Streaming + footer

4. Zaktualizuj requirements.txt:
```
+ pdfplumber==0.11.0
+ python-docx==1.1.0
+ Pillow==10.4.0
```

5. Zaktualizuj main.py â€” dodaj handlery:
```python
# WAÅ»NE: Photo i Document handlery PRZED text handlerem
application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
application.add_handler(MessageHandler(filters.Document.ALL, handle_document))
# ... potem text handler
```

6. Zaktualizuj /help.

Wygeneruj WSZYSTKIE nowe pliki i DOKÅADNE ZMIANY.

## PROMPT: FAZA 5

Realizujesz FAZÄ˜ 5 projektu GigaGrok â€” Collections API + Export.

KONTEKST: Fazy 1-4 zrealizowane.

xAI COLLECTIONS API:
Collections to persistent knowledge stores w xAI. Uploadujesz dokumenty, Grok moÅ¼e po nich szukaÄ‡.

Endpoints (base: https://api.x.ai/v1):
- POST /collections â€” body: {"name": "My Collection"} â†’ {"id": "col_xxx"}
- GET /collections â€” lista kolekcji
- POST /collections/{id}/documents â€” body: multipart file upload
- GET /collections/{id}/documents â€” lista dokumentÃ³w
- DELETE /collections/{id} â€” usuÅ„ kolekcjÄ™

Tool do search:
```json
{
    "type": "function",
    "function": {
        "name": "collections_search",
        "parameters": {"collection_ids": ["col_xxx", "col_yyy"]}
    }
}
```

UWAGA: SprawdÅº aktualnÄ… dokumentacjÄ™ xAI na docs.x.ai â€” API Collections mogÅ‚o siÄ™ zmieniÄ‡.
JeÅ›li Collections API nie jest dostÄ™pne, zaimplementuj lokalne RAG z SQLite FTS5 (Full-Text Search) jako fallback.

ZADANIA:

1. StwÃ³rz handlers/collection.py:

/collection â€” PokaÅ¼ menu/listÄ™ kolekcji:
```
ğŸ“š **Kolekcje** (2 kolekcje)

1. ğŸ“ Dokumentacja projektu (col_abc) â€” 5 dokumentÃ³w
2. ğŸ“ Notatki (col_def) â€” 12 dokumentÃ³w

Komendy:
/collection create <nazwa>
/collection add <id> (reply na plik)
/collection search <id> <query>
/collection list <id>
/collection delete <id>
```

/collection create <nazwa> â€” stwÃ³rz kolekcjÄ™
/collection add <id> â€” reply na plik, upload do kolekcji
/collection search <id> <query> â€” szukaj w kolekcji (uÅ¼yj collections_search tool)
/collection list <id> â€” listuj dokumenty w kolekcji
/collection delete <id> â€” usuÅ„ kolekcjÄ™ (z potwierdzeniem)

2. StwÃ³rz handlers/export.py:

/export â€” Eksport historii:
- DomyÅ›lnie: Markdown format
- /export json â€” JSON format
- /export last 50 â€” ostatnie N wiadomoÅ›ci
- WyÅ›lij jako plik w Telegramie (send_document)

Format Markdown:
```markdown
# GigaGrok â€” Historia konwersacji
Eksport: 2026-02-23 15:30
WiadomoÅ›ci: 156

---

## 2026-02-23 14:00
**User:** Jak dziaÅ‚a Grok 4.1 Fast?
**GigaGrok:** [odpowiedÅº...]
âš™ï¸ grok-4-1-fast-reasoning | ğŸ“¥ 234 ğŸ“¤ 567 | $0.0004

---
```

3. Zmodyfikuj tools.py:
- Dodaj TOOL_COLLECTION_SEARCH z dynamic collection_ids
- Funkcja get_collection_tool(collection_ids: list[str]) -> dict

4. Zmodyfikuj db.py:
- Tabela collections (id, xai_collection_id, name, doc_count, created_at)
- CRUD funkcje

5. Zmodyfikuj grok_client.py:
- Dodaj metody: create_collection(), upload_to_collection(), list_collections(), delete_collection()

6. Zaktualizuj main.py, /help.

Wygeneruj WSZYSTKIE nowe pliki i DOKÅADNE ZMIANY.

## PROMPT: FAZA 6

Realizujesz FAZÄ˜ 6 projektu GigaGrok â€” Voice Chat (STT/TTS).

KONTEKST: Fazy 1-5 zrealizowane.

ZADANIA:

1. StwÃ³rz handlers/voice.py:

STT (Speech-to-Text) â€” Whisper via Groq API (darmowy, ultra-szybki):
```python
# Groq Whisper API:
# POST https://api.groq.com/openai/v1/audio/transcriptions
# Headers: Authorization: Bearer {GROQ_API_KEY}
# Body: multipart/form-data â€” file (audio), model="whisper-large-v3"
# Response: {"text": "transkrypcja..."}
```

TTS (Text-to-Speech) â€” gTTS (darmowy, bez limitu):
```python
from gtts import gTTS
tts = gTTS(text="odpowiedÅº", lang="pl")
tts.save("response.mp3")
# Konwertuj do OGG/OPUS (Telegram wymaga):
# ffmpeg -i response.mp3 -c:a libopus response.ogg
```

Workflow â€” auto-detect voice message:
a. User wysyÅ‚a voice â†’ pobierz OGG z Telegram
b. Transkrybuj via Groq Whisper â†’ tekst
c. PokaÅ¼: "ğŸ¤ Transkrypcja: {tekst}" + "ğŸ§  Grok myÅ›li..."
d. WyÅ›lij tekst do Grok (jak zwykÅ‚y chat)
e. Pobierz odpowiedÅº
f. JeÅ›li voice_enabled: wygeneruj TTS â†’ wyÅ›lij jako voice message + tekst
g. JeÅ›li !voice_enabled: wyÅ›lij tylko tekst

/voice â€” Toggle:
- PrzeÅ‚Ä…cz voice_enabled w user_settings
- "ğŸ”Š Odpowiedzi gÅ‚osowe: WÅÄ„CZONE" / "ğŸ”‡ Odpowiedzi gÅ‚osowe: WYÅÄ„CZONE"

2. Zaktualizuj config.py:
- GROQ_API_KEY: str = "" (opcjonalne â€” jeÅ›li brak, voice STT niedostÄ™pne)

3. Zaktualizuj .env.example:
- GROQ_API_KEY=your_groq_api_key (darmowy z console.groq.com)

4. Zaktualizuj requirements.txt:
```
+ gtts==2.5.0
+ pydub==0.25.1
```

5. README: dodaj info o ffmpeg (sudo apt install ffmpeg)

6. Zaktualizuj main.py:
```python
application.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, handle_voice))
application.add_handler(CommandHandler("voice", voice_toggle))
```

7. Zaktualizuj /help.

Wygeneruj WSZYSTKIE nowe pliki i DOKÅADNE ZMIANY.

## PROMPT: FAZA 7

Realizujesz FAZÄ˜ 7 projektu GigaGrok â€” /gigagrok Full Power Mode.

KONTEKST: Fazy 1-6 zrealizowane. Bot ma: chat, /fast, /think, web search, X search, code exec, analyze, image, files, collections, voice.

KONCEPT: /gigagrok to "tryb boga" â€” Grok dostaje WSZYSTKIE narzÄ™dzia naraz, reasoning na max, i autonomicznie decyduje co uÅ¼yÄ‡.

ZADANIA:

1. StwÃ³rz handlers/gigagrok.py:

/gigagrok <prompt>:
```python
async def gigagrok_command(update, context):
    # Auth check
    prompt = " ".join(context.args) if context.args else None
    
    # JeÅ›li reply na wiadomoÅ›Ä‡ â†’ uÅ¼yj jako kontekst + prompt
    if update.message.reply_to_message:
        reply_text = update.message.reply_to_message.text or ""
        # JeÅ›li reply na zdjÄ™cie â†’ dodaj image analysis
        if update.message.reply_to_message.photo:
            # Pobierz i dodaj jako multimodal
            pass
        prompt = f"Kontekst:\n{reply_text}\n\nZapytanie:\n{prompt or 'Przeanalizuj powyÅ¼sze.'}"
    
    if not prompt:
        await update.message.reply_text("Podaj prompt po /gigagrok")
        return
    
    # Pobierz collections (jeÅ›li istniejÄ…)
    collections = await db.get_collections(user_id)
    collection_ids = [c["xai_collection_id"] for c in collections]
    
    # Zbuduj tools â€” WSZYSTKO
    tools = list(TOOLS_ALL)  # web, x, code
    if collection_ids:
        tools.append(get_collection_tool(collection_ids))
    
    # System prompt â€” FULL POWER
    gigagrok_system = """JesteÅ› w trybie GIGAGROK â€” PEÅNA MOC.

Masz dostÄ™p do narzÄ™dzi:
ğŸŒ Web Search â€” szukaj aktualnych informacji w internecie
ğŸ¦ X Search â€” szukaj na X/Twitter
âš¡ Code Execution â€” uruchamiaj kod w sandboxie
ğŸ“š Collections Search â€” szukaj w bazie wiedzy uÅ¼ytkownika

STRATEGIA:
1. MYÅšL GÅÄ˜BOKO â€” full reasoning, nie spiesz siÄ™
2. JeÅ›li potrzebujesz aktualnych danych â†’ web_search
3. JeÅ›li potrzebujesz opinii/trendÃ³w â†’ x_search
4. JeÅ›li potrzebujesz obliczeÅ„/wizualizacji â†’ code_execution
5. JeÅ›li temat dotyczy bazy wiedzy â†’ collections_search
6. KOMBINUJ narzÄ™dzia w Å‚aÅ„cuchy (np. web_search â†’ code_execution do analizy)
7. Daj KOMPLETNÄ„, wyczerpujÄ…cÄ… odpowiedÅº
8. Strukturyzuj: problem â†’ analiza â†’ wnioski â†’ rekomendacje

Aktualna data: {current_date}
""" + ("\nUser ma kolekcje: " + ", ".join(c["name"] for c in collections) if collections else "")
    
    # Status updates mapping
    tool_status = {
        "web_search": "ğŸŒ Szukam w internecie...",
        "x_search": "ğŸ¦ Sprawdzam X/Twitter...",
        "code_execution": "âš¡ Uruchamiam kod...",
        "collections_search": "ğŸ“š Szukam w kolekcjach...",
    }
    
    # Stream z rozbudowanymi status updates
    sent = await update.message.reply_text("ğŸš€ <b>GIGAGROK MODE</b>\nğŸ§  Reasoning...", parse_mode="HTML")
    
    # ... streaming logic z tool_use events pokazujÄ…cymi statusy
    # Na koniec footer z:
    # ğŸš€ GIGAGROK | model | ğŸ“¥ tokens ğŸ“¤ tokens ğŸ§  reasoning | ğŸ”§ web_search, code_execution | ğŸ’° $cost | â± time
```

2. Zmodyfikuj utils.py:
- format_gigagrok_footer() â€” rozbudowany footer z listÄ… uÅ¼ytych narzÄ™dzi

3. Zaktualizuj main.py:
```python
application.add_handler(CommandHandler("gigagrok", gigagrok_command))
```

4. Zaktualizuj /help.

Wygeneruj KOMPLETNY handlers/gigagrok.py i DOKÅADNE ZMIANY w pozostaÅ‚ych plikach.

## PROMPT: FAZA 8

Realizujesz FAZÄ˜ 8 projektu GigaGrok â€” GitHub Integration + Live Workspace.

KONTEKST: Fazy 1-7 zrealizowane.

ZADANIA:

1. StwÃ³rz github_client.py:
```python
class GitHubClient:
    """Operacje Git na VM."""
    
    def __init__(self, workspace_dir: str = "/home/user/workspaces"):
        self.workspace_dir = Path(workspace_dir)
        self.workspace_dir.mkdir(parents=True, exist_ok=True)
    
    async def clone_or_pull(self, repo_url: str) -> Path:
        """Clone repo lub pull jeÅ›li istnieje. ZwrÃ³Ä‡ Å›cieÅ¼kÄ™."""
    
    async def get_file_tree(self, repo_path: Path, max_depth: int = 3) -> str:
        """ZwrÃ³Ä‡ drzewko plikÃ³w."""
    
    async def read_file(self, repo_path: Path, file_path: str) -> str:
        """Odczytaj plik z repo."""
    
    async def write_file(self, repo_path: Path, file_path: str, content: str):
        """Zapisz plik do repo."""
    
    async def commit_and_push(self, repo_path: Path, message: str) -> str:
        """Commit all changes i push."""
    
    async def create_pr(self, repo_url: str, title: str, body: str, branch: str) -> str:
        """StwÃ³rz PR via GitHub API. ZwrÃ³Ä‡ URL."""
```

Wszystkie operacje git via subprocess.

2. StwÃ³rz handlers/github.py:

/github <repo_url> <task> â€” Klonuj i analizuj:
- Clone/pull repo
- Pobierz file tree
- WyÅ›lij do Grok z kontekstem: "Repo structure:\n{tree}\n\nTask: {task}"
- tools=[TOOL_CODE_EXEC] â€” Grok moÅ¼e uruchomiÄ‡ kod do analizy
- Streaming + footer

/github commit <message> â€” Commituj zmiany
/github pr <title> â€” StwÃ³rz Pull Request

3. StwÃ³rz handlers/workspace.py:

/workspace set <path> â€” Ustaw folder roboczy:
- Whitelist: /home/user/*, /opt/*
- Zapisz do user_settings
- PokaÅ¼ strukturÄ™ folderu

/workspace â€” PokaÅ¼ aktualny workspace
/workspace ls [subpath] â€” Listuj pliki
/workspace read <file> â€” Odczytaj plik, dodaj do nastÄ™pnego zapytania
/workspace write <file> â€” Grok wygenerowaÅ‚ kod? Zapisz do pliku

4. BezpieczeÅ„stwo:
- WORKSPACE_WHITELIST w config: lista dozwolonych bazowych Å›cieÅ¼ek
- Walidacja path traversal (no .., no absolute paths outside whitelist)
- Max file size do odczytu: 1MB

5. Zaktualizuj config.py:
- GITHUB_TOKEN: str = ""
- WORKSPACE_BASE: str = "/home/user/workspaces"
- WORKSPACE_WHITELIST: list[str] = ["/home/user", "/opt"]

6. Zaktualizuj main.py, /help.

Wygeneruj WSZYSTKIE nowe pliki i DOKÅADNE ZMIANY.

## PROMPT: FAZA 9

Realizujesz FAZÄ˜ 9 projektu GigaGrok â€” Production Deploy na GCE e2-micro.

KONTEKST: Fazy 1-8 zrealizowane. Bot dziaÅ‚a na e2-standard-8 z kredytami do 13 marca.

ZADANIA â€” stwÃ³rz pliki deployment:

1. setup_vm.sh â€” Setup skrypt dla nowej e2-micro (us-central1):
```bash
#!/bin/bash
# GigaGrok Production Setup for GCE e2-micro (Ubuntu 24.04)
set -euo pipefail

# System update
sudo apt update && sudo apt upgrade -y

# Python 3.12
sudo apt install -y python3.12 python3.12-venv python3-pip

# System deps
sudo apt install -y ffmpeg git curl

# Cloudflared
curl -L https://pkg.cloudflare.com/cloudflare-main.gpg | sudo tee /usr/share/keyrings/cloudflare-main.gpg >/dev/null
echo 'deb [signed-by=/usr/share/keyrings/cloudflare-main.gpg] https://pkg.cloudflare.com/cloudflared any main' | sudo tee /etc/apt/sources.list.d/cloudflared.list
sudo apt update && sudo apt install -y cloudflared

# User
sudo useradd -r -m -s /bin/bash gigagrok

# Clone repo
sudo -u gigagrok git clone https://ghp_TOKEN@github.com/USER/gigagrok-bot.git /opt/gigagrok
cd /opt/gigagrok

# Venv
sudo -u gigagrok python3.12 -m venv venv
sudo -u gigagrok ./venv/bin/pip install -r requirements.txt

# .env
sudo -u gigagrok cp .env.example .env
echo ">>> EDYTUJ /opt/gigagrok/.env z kluczami API"

# Systemd
sudo cp gigagrok.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable gigagrok

echo ">>> Setup complete. Edit .env then: sudo systemctl start gigagrok"
```

2. gigagrok.service â€” systemd unit:
```ini
[Unit]
Description=GigaGrok Telegram Bot
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
User=gigagrok
Group=gigagrok
WorkingDirectory=/opt/gigagrok
ExecStart=/opt/gigagrok/venv/bin/python main.py
Restart=always
RestartSec=10
Environment=PYTHONUNBUFFERED=1

# Security hardening
NoNewPrivileges=true
ProtectSystem=strict
ProtectHome=read-only
ReadWritePaths=/opt/gigagrok
PrivateTmp=true

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=gigagrok

[Install]
WantedBy=multi-user.target
```

3. deploy.sh â€” Quick deploy (uruchamiaj z dev VM lub lokalnie):
```bash
#!/bin/bash
# Deploy latest code to production
set -euo pipefail

PROD_VM="gigagrok-prod"  # GCE instance name
ZONE="us-central1-c"

echo "ğŸš€ Deploying GigaGrok..."
gcloud compute ssh $PROD_VM --zone=$ZONE --command="
    cd /opt/gigagrok &&
    sudo -u gigagrok git pull &&
    sudo -u gigagrok ./venv/bin/pip install -r requirements.txt --quiet &&
    sudo systemctl restart gigagrok &&
    sleep 3 &&
    sudo systemctl status gigagrok --no-pager
"
echo "âœ… Deploy complete"
```

4. healthcheck.py â€” Prosty HTTP healthcheck (port 8080):
```python
# Uruchamia siÄ™ w osobnym wÄ…tku w main.py
# GET /health â†’ {"status":"ok","uptime":"2d 5h","last_message":"2m ago","db_size":"2.3MB"}
# Monitoring: uptimerobot.com (darmowy, sprawdza co 5 min)
```

5. backup.sh â€” Backup DB:
```bash
#!/bin/bash
# Cron: 0 3 * * * /opt/gigagrok/backup.sh
TIMESTAMP=$(date +%Y%m%d_%H%M)
cp /opt/gigagrok/gigagrok.db /tmp/gigagrok_${TIMESTAMP}.db
gsutil cp /tmp/gigagrok_${TIMESTAMP}.db gs://gigagrok-backups/
rm /tmp/gigagrok_${TIMESTAMP}.db
# Zachowaj ostatnie 30 backupÃ³w
gsutil ls gs://gigagrok-backups/ | head -n -30 | xargs -r gsutil rm
```

6. Zaktualizuj main.py â€” dodaj healthcheck thread.

7. Zaktualizuj README.md â€” sekcja Production Deployment.

Wygeneruj WSZYSTKIE pliki deployment, kompletne, gotowe do uÅ¼ycia.

## PROMPT: END

Wszystkie fazy zrealizowane. Bot GigaGrok jest gotowy do produkcji.
